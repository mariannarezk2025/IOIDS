{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries  \n",
    "- `pandas` and `numpy`: For handling and processing data.  \n",
    "- `train_test_split`: Splits the dataset into training and testing sets.  \n",
    "- `LabelEncoder`: Converts categorical labels into numerical values.  \n",
    "- `MinMaxScaler`: Normalizes features to a range between 0 and 1.  \n",
    "- `Sequential`: Defines a neural network model.  \n",
    "- `Dense` and `Dropout`: Layers for building the neural network.  \n",
    "- `to_categorical`: Converts labels into a one-hot encoded format for classification.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Preprocessing the Data  \n",
    "- Loads the dataset **`selected_features_training.csv`**.  \n",
    "- **Separates features (`X`)** and the **target variable (`y`)**.  \n",
    "- `X` contains the selected features, and `y` contains the class labels for classification.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('selected_features_training.csv')\n",
    "\n",
    "# Step 3: Preprocess the Data\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the Target Variable  \n",
    "- Uses `LabelEncoder` to **convert categorical labels into numerical values**.  \n",
    "- Applies `to_categorical` to **one-hot encode** the labels for multi-class classification.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Data into Training and Testing Sets  \n",
    "- **Splits the dataset** into **80% training** and **20% testing** using `train_test_split`.  \n",
    "- Ensures reproducibility with `random_state=42`.  \n",
    "- `y_train.shape[1]` gives the **number of unique classes** in the target variable.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Neural Network Model  \n",
    "- Uses a **Sequential model** to build a feedforward neural network.  \n",
    "- **First layer**:  \n",
    "  - `Dense(1024)`: 1024 neurons with **ReLU activation**.  \n",
    "  - `input_dim=X_train.shape[1]`: Matches the number of input features.  \n",
    "  - `Dropout(0.5)`: Reduces overfitting by randomly dropping 50% of neurons.  \n",
    "- **Second layer**:  \n",
    "  - `Dense(64)`: 64 neurons with **ReLU activation**.  \n",
    "  - `Dropout(0.5)`: Again, prevents overfitting.  \n",
    "- **Output layer**:  \n",
    "  - `Dense(y_train.shape[1], activation='softmax')`: Outputs probabilities for multi-class classification using **Softmax activation**.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Marianna PHD\\Haute Alsace\\New Contribution\\IOIDS\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.5))  # Introduce probabilistic elements\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the Model  \n",
    "- **Optimizer**: `adam` (Adaptive Moment Estimation) for efficient learning.  \n",
    "- **Loss Function**: `categorical_crossentropy`, suitable for multi-class classification.  \n",
    "- **Metrics**: `accuracy` to track the model’s performance.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model  \n",
    "- **Trains the neural network** using the training data (`X_train`, `y_train`).  \n",
    "- **Epochs**: `50` (number of times the model sees the dataset).  \n",
    "- **Batch Size**: `64` (number of samples processed before updating the model).  \n",
    "- **Validation Split**: `0.1` (10% of training data is used for validation).  \n",
    "- Helps monitor performance and avoid overfitting.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9048 - loss: 0.4531 - val_accuracy: 0.9638 - val_loss: 0.1142\n",
      "Epoch 2/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9625 - loss: 0.1285 - val_accuracy: 0.9735 - val_loss: 0.0813\n",
      "Epoch 3/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9679 - loss: 0.1050 - val_accuracy: 0.9721 - val_loss: 0.0736\n",
      "Epoch 4/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9712 - loss: 0.0899 - val_accuracy: 0.9767 - val_loss: 0.0649\n",
      "Epoch 5/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9735 - loss: 0.0835 - val_accuracy: 0.9798 - val_loss: 0.0758\n",
      "Epoch 6/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9748 - loss: 0.0778 - val_accuracy: 0.9803 - val_loss: 0.0588\n",
      "Epoch 7/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9766 - loss: 0.0750 - val_accuracy: 0.9809 - val_loss: 0.0601\n",
      "Epoch 8/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9773 - loss: 0.0727 - val_accuracy: 0.9801 - val_loss: 0.0567\n",
      "Epoch 9/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9774 - loss: 0.0710 - val_accuracy: 0.9835 - val_loss: 0.0517\n",
      "Epoch 10/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9779 - loss: 0.0690 - val_accuracy: 0.9817 - val_loss: 0.0528\n",
      "Epoch 11/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9782 - loss: 0.0689 - val_accuracy: 0.9829 - val_loss: 0.0525\n",
      "Epoch 12/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9795 - loss: 0.0635 - val_accuracy: 0.9830 - val_loss: 0.0515\n",
      "Epoch 13/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9792 - loss: 0.0633 - val_accuracy: 0.9847 - val_loss: 0.0501\n",
      "Epoch 14/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9787 - loss: 0.0647 - val_accuracy: 0.9845 - val_loss: 0.0478\n",
      "Epoch 15/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9796 - loss: 0.0641 - val_accuracy: 0.9833 - val_loss: 0.0487\n",
      "Epoch 16/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9804 - loss: 0.0622 - val_accuracy: 0.9842 - val_loss: 0.0483\n",
      "Epoch 17/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9796 - loss: 0.0608 - val_accuracy: 0.9830 - val_loss: 0.0487\n",
      "Epoch 18/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9805 - loss: 0.0589 - val_accuracy: 0.9847 - val_loss: 0.0464\n",
      "Epoch 19/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9807 - loss: 0.0553 - val_accuracy: 0.9837 - val_loss: 0.0482\n",
      "Epoch 20/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9813 - loss: 0.0574 - val_accuracy: 0.9854 - val_loss: 0.0464\n",
      "Epoch 21/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9802 - loss: 0.0597 - val_accuracy: 0.9844 - val_loss: 0.0473\n",
      "Epoch 22/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9818 - loss: 0.0558 - val_accuracy: 0.9844 - val_loss: 0.0462\n",
      "Epoch 23/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9800 - loss: 0.0582 - val_accuracy: 0.9843 - val_loss: 0.0458\n",
      "Epoch 24/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9814 - loss: 0.0574 - val_accuracy: 0.9846 - val_loss: 0.0453\n",
      "Epoch 25/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9819 - loss: 0.0545 - val_accuracy: 0.9858 - val_loss: 0.0435\n",
      "Epoch 26/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9813 - loss: 0.0529 - val_accuracy: 0.9852 - val_loss: 0.0451\n",
      "Epoch 27/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9826 - loss: 0.0553 - val_accuracy: 0.9848 - val_loss: 0.0456\n",
      "Epoch 28/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9815 - loss: 0.0549 - val_accuracy: 0.9848 - val_loss: 0.0469\n",
      "Epoch 29/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9818 - loss: 0.0543 - val_accuracy: 0.9857 - val_loss: 0.0434\n",
      "Epoch 30/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9828 - loss: 0.0512 - val_accuracy: 0.9845 - val_loss: 0.0442\n",
      "Epoch 31/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9821 - loss: 0.0530 - val_accuracy: 0.9854 - val_loss: 0.0425\n",
      "Epoch 32/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9825 - loss: 0.0508 - val_accuracy: 0.9851 - val_loss: 0.0439\n",
      "Epoch 33/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9824 - loss: 0.0556 - val_accuracy: 0.9847 - val_loss: 0.0458\n",
      "Epoch 34/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9813 - loss: 0.0560 - val_accuracy: 0.9849 - val_loss: 0.0446\n",
      "Epoch 35/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9823 - loss: 0.0516 - val_accuracy: 0.9856 - val_loss: 0.0455\n",
      "Epoch 36/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9820 - loss: 0.0535 - val_accuracy: 0.9855 - val_loss: 0.0427\n",
      "Epoch 37/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9826 - loss: 0.0538 - val_accuracy: 0.9854 - val_loss: 0.0441\n",
      "Epoch 38/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9827 - loss: 0.0532 - val_accuracy: 0.9863 - val_loss: 0.0421\n",
      "Epoch 39/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9831 - loss: 0.0503 - val_accuracy: 0.9858 - val_loss: 0.0435\n",
      "Epoch 40/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9827 - loss: 0.0520 - val_accuracy: 0.9842 - val_loss: 0.0438\n",
      "Epoch 41/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9831 - loss: 0.0508 - val_accuracy: 0.9865 - val_loss: 0.0436\n",
      "Epoch 42/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9831 - loss: 0.0507 - val_accuracy: 0.9856 - val_loss: 0.0456\n",
      "Epoch 43/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9821 - loss: 0.0537 - val_accuracy: 0.9860 - val_loss: 0.0423\n",
      "Epoch 44/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9833 - loss: 0.0501 - val_accuracy: 0.9859 - val_loss: 0.0424\n",
      "Epoch 45/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9831 - loss: 0.0515 - val_accuracy: 0.9864 - val_loss: 0.0424\n",
      "Epoch 46/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9841 - loss: 0.0490 - val_accuracy: 0.9855 - val_loss: 0.0446\n",
      "Epoch 47/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9834 - loss: 0.0504 - val_accuracy: 0.9845 - val_loss: 0.0437\n",
      "Epoch 48/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9821 - loss: 0.0522 - val_accuracy: 0.9863 - val_loss: 0.0442\n",
      "Epoch 49/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9829 - loss: 0.0489 - val_accuracy: 0.9864 - val_loss: 0.0438\n",
      "Epoch 50/50\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9831 - loss: 0.0504 - val_accuracy: 0.9869 - val_loss: 0.0410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x161e5848ad0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=50, batch_size=64, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Model  \n",
    "- Tests the trained model on **unseen test data (`X_test`, `y_test`)**.  \n",
    "- `model.evaluate()` returns:  \n",
    "  - **Loss**: Measures the model's error.  \n",
    "  - **Accuracy**: The percentage of correct predictions.  \n",
    "- Prints the **final test accuracy** to assess model performance.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m788/788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9856 - loss: 0.0536\n",
      "Test Accuracy: 0.9858\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Trained Model  \n",
    "- Saves the trained neural network model to a file **`pnn_model.h5`**.  \n",
    "- Allows reloading the model later without retraining.  \n",
    "- Useful for deployment or further evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(filepath=\"pnn_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions and Evaluating Performance  \n",
    "\n",
    "1. **Make Predictions**  \n",
    "   - Converts probability scores into class labels using `np.argmax()`.  \n",
    "\n",
    "2. **Convert True Labels**  \n",
    "   - Transforms one-hot encoded labels into class labels.  \n",
    "\n",
    "3. **Import Metrics**  \n",
    "   - Uses accuracy, precision, recall, F1-score, and classification report.  \n",
    "   - Adds **False Positive Rate (FPR)** and **Specificity (True Negative Rate)**.  \n",
    "\n",
    "4. **Calculate Performance Metrics**  \n",
    "   - **Accuracy**: Overall correctness of predictions.  \n",
    "   - **Precision**: Percentage of predicted positives that are actually correct.  \n",
    "   - **Recall**: Percentage of actual positives correctly identified.  \n",
    "   - **F1 Score**: Balances precision and recall.  \n",
    "   - **FPR (False Positive Rate)**: Measures incorrect positive predictions.  \n",
    "   - **Specificity**: Measures the model's ability to correctly identify negatives.  \n",
    "\n",
    "5. **Print Classification Report**  \n",
    "   - Displays metrics for each class, including precision, recall, and F1-score.  \n",
    "\n",
    "⚠️ **Note**: FPR and Specificity are only computed for **binary classification**.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m788/788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Accuracy: 0.9858\n",
      "Precision: 0.9850\n",
      "Recall: 0.9858\n",
      "F1 Score: 0.9853\n",
      "FPR and Specificity are not computed for multi-class classification.\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.72      0.74       185\n",
      "           1       0.00      0.00      0.00         9\n",
      "           3       1.00      0.82      0.90        11\n",
      "           4       0.50      1.00      0.67         1\n",
      "           5       0.95      0.97      0.96       733\n",
      "           6       0.17      0.33      0.22         3\n",
      "           9       1.00      1.00      1.00      8228\n",
      "          10       0.96      0.96      0.96       313\n",
      "          11       0.98      0.99      0.99     13422\n",
      "          12       0.00      0.00      0.00         1\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       1.00      0.93      0.96        43\n",
      "          15       1.00      0.98      0.99       573\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.97      0.91      0.94       738\n",
      "          18       1.00      0.99      1.00       534\n",
      "          19       0.00      0.00      0.00         1\n",
      "          20       1.00      1.00      1.00       188\n",
      "          21       0.97      0.75      0.85       202\n",
      "          22       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.99     25195\n",
      "   macro avg       0.61      0.62      0.61     25195\n",
      "weighted avg       0.99      0.99      0.99     25195\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Marianna PHD\\Haute Alsace\\New Contribution\\IOIDS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Marianna PHD\\Haute Alsace\\New Contribution\\IOIDS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Marianna PHD\\Haute Alsace\\New Contribution\\IOIDS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Marianna PHD\\Haute Alsace\\New Contribution\\IOIDS\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred_prob = model.predict(X_test)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Convert true labels from one-hot encoding to class labels\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Import necessary metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Extract TN, FP, FN, TP for binary classification (assuming a 2-class problem)\n",
    "if conf_matrix.shape == (2, 2):\n",
    "    TN, FP, FN, TP = conf_matrix.ravel()\n",
    "\n",
    "    # Calculate False Positive Rate (FPR)\n",
    "    FPR = FP / (FP + TN)\n",
    "    print(f'False Positive Rate (FPR): {FPR:.4f}')\n",
    "\n",
    "    # Calculate Specificity (True Negative Rate)\n",
    "    specificity = TN / (TN + FP)\n",
    "    print(f'Specificity: {specificity:.4f}')\n",
    "else:\n",
    "    print(\"FPR and Specificity are not computed for multi-class classification.\")\n",
    "\n",
    "# Optional: Generate a classification report\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
